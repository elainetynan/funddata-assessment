# funddata-assessment


04/01/2023
----------
Added information on the binomial distribution.
Did some cleanup and sorted bibliography and table of contents.


02/01/2023
----------
In Normal Distribution Notebook, working on the Cumulative Distribution Function.
Added information on the Probability Point Function (Inverse Distribution Function).


31/12/2022
----------
In Normal Distribution Notebook, added information and graphs on how the mean and standard deviation affect the normal distribution curve.
Put in tests for the empirical rules, Kurtosis and skewness of normal distribution for all 3 datasets.
Started work on the Cumulative Distribution Function.



30/12/2022
----------
In Normal Distribution Notebook, added a new histogram with a bell curve line graph.
Created table of contents.
Researching and writing-up on the Probability Distribution Function.

Did some clean-up of practicals.


26/12/2022
----------
In Normal Distribution Notebook I created a random set of 10,000 normally distributed values. I then did 4 different types of tests to verify that the data was in fact a Normal Distribution. As expected, all tests showed that the data was normally distributed.

Next I created a random set of 10,000 chisquare distributed values. I then did 4 different types of tests to verify that the data was not a Normal Distribution. As expected, all tests showed that the data was not normally distributed.

Finally I carried out the same 4 tests on the data I had extracted from Kaggle. In this case 2 tests showed the data was normally distributed and the other 2 initially seemed to show that the data was not a normal distribution. On further inspection, with some research, I was able to conclude that the data was in fact a normal distribution.

Did some clean-up of practicals.


22/12/2022
----------
Working on Normal Distribution notebook.
Using the data from Kaggle I sorted the data based on profit and then add a column categorising each profit value into 1 of 10 bins. Then I calculated the count of values in each bin. Next I sorted the data on the bins and finally I did a bar chart of the data that showed the normal distribution of the data.


18/12/2022
----------
Exracted data from Kaggle .com. Data is a sample of normally distributed data.


16/12/2022
----------
Completed the notebook, videos and exercise for Cleansing part 2


08/12/2022
----------
Working on the Project on Normal Distribution.
Did a little more research on Normal Distribution.
Started to lay out the notebook better.
Took note of some interesting online finds in relation to Normal Distribution.


06/12/2022
----------
Completed the notebook, videos and exercise on Cleansing.


01/12/2022
----------
I forgot to update this and push to git hub the end of last week
Completed Outliers (Box Plots, LaTex, Best Fit, etc) videos, notes and Exercises.


21/11/2022
----------
Completed videos and notebook on Outliers.


15/11/2022
----------
Completed notebook on Bias and 2 exercises included.
Started notebook for Normal distribution and did a some research.


13/11/2022
----------
Continuing with Bias.


09/11/2022
----------
Added the windows git ignore details to ignore unnecessary files to see in github.

Also working with Bias, cognitive bias, statistical bias, etc.


27/10/2022
----------
Continuing with randomness.
Looking at numpy and various distributions.
Used matplotlib to plot the distributions.
Completed Exercise 3 in notebook.


20/10/2022
----------
Worked through exercies on Randomness.
I was familiar with probability and some coin flip examples so this was nice to learn new stuff with a familiar backdrop.
Exercises 1 and 2 completed in notebook.


13/10/2022
----------
Tried the code from the class. Made minor changes to make it easier to read for myself.
The class code was on Entropy. It investigates the entropy of a randomly generated strings (0s and 1s) as well as the entropy of Fire Alarms and Pincodes.

Added an explanation (in my own words) as to why the log of zero is not defined.


04/10/2022
----------
Modified code written by lecturer (Ian McLoughlin)
Code modified to output 1000 characters instead of the same length as the paragraph from Alice in Wonderland.
Code also modified to calculate the weightings of the next probable character (from a list of letters and the space generated from the Alice in Wonderland excerpt) based on the 2 previous characters as oposed to just the 1 previous character.
Result seems to be correct and is quite pleasing as the generated exerpt is another step closer to the English language.
